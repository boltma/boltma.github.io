[{"title":"Fisher Information","date":"2019-05-02T14:49:24.000Z","path":"2019/05/02/Fisher-Information/","text":"Fisher Information Fisher Information（费希尔信息）是用以衡量观测数据所蕴含的数据量，具体说来是指观测所得的随机变量\\(X\\)携带的关于未知参数\\(\\theta\\)的信息量，其中\\(X\\)的概率分布依赖于\\(\\theta\\)，通常记作\\({\\mathcal {I}}_{X}(\\theta)\\)。 对于概率分布\\(f(X;\\theta)\\)（满足\\(f(x;\\theta )\\geq0, \\int f(x;\\theta )dx=1,\\quad\\forall\\theta\\in\\Theta\\)，\\(\\Theta\\)为参数集），称对数似然函数关于\\(\\theta\\)的偏导\\(\\frac {\\partial }{\\partial \\theta }\\log f(X;\\theta )\\)为其得分（Score function），对于真实的参数\\(\\theta\\)，则有此得分的期望为0： \\({\\displaystyle {\\begin{aligned}\\operatorname {E} \\left[\\left.{\\frac {\\partial }{\\partial \\theta }}\\log f(X;\\theta )\\right|\\theta \\right]&amp;=\\int {\\frac { {\\frac {\\partial }{\\partial \\theta }}f(x;\\theta )}{f(x;\\theta )}}f(x;\\theta )\\,dx\\\\&amp;={\\frac {\\partial }{\\partial \\theta }}\\int f(x;\\theta )\\,dx\\\\&amp;={\\frac {\\partial }{\\partial \\theta }}1=0.\\end{aligned}}}\\) 并将得分的方差定义为费希尔信息： \\({\\displaystyle {\\mathcal {I}}(\\theta )=\\operatorname {E} \\left[\\left.\\left({\\frac {\\partial }{\\partial \\theta }}\\log f(X;\\theta )\\right)^{2}\\right|\\theta \\right]=\\int \\left({\\frac {\\partial }{\\partial \\theta }}\\log f(x;\\theta )\\right)^{2}f(x;\\theta )\\,dx}\\) 并且在密度函数具有良好性质的情况下，可以用分部积分很容易证明： \\({\\mathcal {I}}(\\theta )=-\\operatorname {E} \\left[\\left.{\\frac {\\partial ^{2}}{\\partial \\theta ^{2}}}\\log f(X;\\theta )\\right|\\theta \\right]\\) 这个表达式以如下方式表达了观测所携带的信息量：若对数似然函数较为平坦，则我们对\\(\\theta\\)的估计较差，反之，若对数似然函数有高而窄的峰，则我们可以得到对\\(\\theta\\)的较好估计，而这个性状由负二阶导数表征。 由于n个样本的对数似然函数为单个似然函数之和，容易证明，n个独立同分布样本的费希尔信息是单个样本的费希尔信息的n倍。 费希尔信息的三种观点： 得分（对数似然函数的偏导）的方差 对数似然函数负二阶偏导的期望 最大似然估计渐近分布的方差的倒数 Cramér-Rao Bound 费希尔信息的重要性在于Cramér-Rao不等式，或Cramér-Rao Bound（克拉美罗界）： 费希尔信息的倒数是参数\\(\\theta\\)的任何无偏估计\\(\\hat\\theta\\)的方差的下界，即\\(\\operatorname {var} ({\\hat {\\theta }})\\geq {\\frac {1}{\\mathcal {I}(\\theta )}}\\) 关于参数\\(\\theta\\)的估计\\(\\hat\\theta\\)的偏定义为估计的误差的期望值，即\\(\\operatorname {Bias} _{\\theta }[\\,{\\hat {\\theta }}\\,]=\\operatorname {E} _{\\theta }[\\,{\\hat {\\theta }}\\,]-\\theta =\\operatorname {E} _{\\theta }[\\,{\\hat {\\theta }}-\\theta \\,]\\)，其中\\(\\operatorname {E} _{\\theta }\\)表示期望是相对密度函数\\(f(X;\\theta)\\)而言的。 若对于所有\\(\\theta\\in\\Theta\\)，偏为0，则称此估计为无偏估计。 例如样本均值是总体均值的无偏估计量，样本方差是总体方差的无偏估计量，而标准差是总体标准差的有偏估计量。 估计无偏并不能保证误差以极大的概率是低的。例如对于正态分布\\({\\mathcal {N}}(\\theta ,1)\\)，设\\(X_1,X_2,\\cdots,X_n\\)是抽自它的独立同分布样本。估计\\(\\theta\\)时，\\(X_1\\)与\\(\\bar {X_n}\\)均为无偏估计，然而显然使用更多数据会得到更好的估计，事实上也可以证明\\(\\bar {X_n}\\)是最小方差无偏估计量，也即达到了克拉美罗界。 达到克拉美罗界的无偏估计量优越于其他所有估计，也即\\({\\displaystyle \\operatorname{E}[(\\hat\\theta_1(X_1,X_2,\\cdots,X_n)-\\theta)^{2}]\\leq\\operatorname{E}[(\\hat\\theta_2(X_1,X_2,\\cdots,X_n)-\\theta)^{2}]}\\)，若\\(\\hat\\theta_1\\)达到了克拉美罗界。 Cramér-Rao不等式的证明： 设\\(V\\)是得分函数，\\(\\hat\\theta\\)是估计量。由Cauchy-Schwartz不等式，可得 \\[\\operatorname{E}_\\theta[(V-\\operatorname{E}_\\theta V)(\\hat\\theta-\\operatorname{E}_\\theta\\hat\\theta)] \\leq \\operatorname{E}_\\theta(V-\\operatorname{E}_\\theta V)^2\\operatorname{E}_\\theta(\\hat\\theta-\\operatorname{E}_\\theta \\hat\\theta)^2\\] 由于\\(\\hat\\theta\\)是无偏估计，所以对于任意\\(\\theta\\)均有\\(\\operatorname{E}_\\theta \\hat\\theta=\\theta\\)，同时得分函数的期望也为零（见上），并且结合费希尔信息的定义（\\({\\mathcal {I}}(\\theta )=\\operatorname {E}[V^2]\\)），代入上式有\\(\\operatorname {E}_\\theta[V\\hat\\theta]\\leq\\mathcal{I}(\\theta)\\operatorname{var}(\\hat\\theta).\\) 而 \\[{\\displaystyle \\begin{aligned} \\operatorname {E}_\\theta[V\\hat\\theta]&amp;=\\int\\frac{\\frac{\\partial}{\\partial\\theta}f(x;\\theta)}{f(x;\\theta)}\\hat\\theta(x)f(x;\\theta)dx \\\\ &amp;= \\int \\frac{\\partial}{\\partial\\theta} f(x;\\theta)\\hat\\theta(x)dx \\\\ &amp;= \\frac{\\partial}{\\partial\\theta}\\int f(x;\\theta)\\hat\\theta(x)dx \\\\ &amp;= \\frac{\\partial}{\\partial\\theta} \\operatorname{E}_\\theta[\\hat\\theta] \\\\ &amp;= \\frac{\\partial}{\\partial\\theta}\\theta = 1\\end{aligned}}\\] （这里能交换积分与微分号是假定密度函数具有良好性质，上同） 代入即得到Cramér-Rao不等式。 \\(\\square\\) 以相同的证明方式可以得到对于任意估计量有\\(\\operatorname {var} \\left({\\hat {\\theta }}\\right)\\geq {\\frac {[1+b&#39;(\\theta )]^{2}}{\\mathcal{I}(\\theta )}}\\)，此处\\(b(\\theta)=\\operatorname{E}_\\theta[\\hat\\theta]-\\theta.\\) 多参数情形的Fisher Information 多参数下有费希尔信息矩阵\\(\\mathcal{I}(\\theta)\\)，其中元素为\\(\\mathcal{I}_{m,k}=\\operatorname {E} \\left[{\\frac {\\partial }{\\partial \\theta _{m}}}\\log f\\left(x;\\theta\\right){\\frac {\\partial }{\\partial \\theta _{k}}}\\log f\\left(x;\\theta\\right)\\right]=-\\operatorname {E} \\left[{\\frac {\\partial ^{2}}{\\partial \\theta _{m}\\partial \\theta _{k}}}\\log f\\left(x;\\theta\\right)\\right]\\) Cramér-Rao不等式变为：\\(\\Sigma\\geq\\mathcal{I}^{-1}(\\theta)\\)，这里矩阵不小于号指差是半正定的，\\(\\Sigma\\)是关于\\(\\theta\\)的一组无偏估计量的协方差矩阵。 与其它散度测度的关系 与熵的关系 以\\(f(x)\\)为密度函数的随机变量\\(X\\)的微分熵（differential entropy）定义为： \\[h(x)=-\\int_{S}f(x)\\log f(x)dx\\] 对\\(\\epsilon&gt;0\\)及任意\\(n\\)，定义\\(f(x)\\)的典型集\\(A_{\\epsilon}^{(n)}\\)如下： \\[\\begin{aligned} A_{\\epsilon}^{(n)}=\\{&amp;(x_1,x_2,\\cdots,x_n)\\in S^n: \\\\ &amp;\\left|-\\frac{1}{n}\\log f(x_1,x_2,\\cdots,x_n)-h(X)\\right|\\leq\\epsilon \\} \\end{aligned}\\] 这里\\(f(x_1,x_2,\\cdots,x_n) = \\prod\\limits_{i=1}^{n}f(x_i)\\) 典型集是所有概率\\(\\geq1-\\epsilon\\)的集合中体积最小的。 熵表征了典型集的体积（典型集体积渐近趋于\\(2^{nh}\\)，其中\\(h\\)为熵），而费希尔信息与典型集的表面积相关。 de Bruijn恒等式 设\\(X\\)为任一随机变量，其密度函数为\\(f(x)\\)且方差有限。令\\(Z\\)是与\\(X\\)独立的正态分布的随机变量，均值为0，方差为1。则： \\[\\frac{\\partial}{\\partial t}h_e(X+\\sqrt{t}Z)=\\frac{1}{2}\\mathcal{I}(X+\\sqrt{t}Z)\\] 此处\\(h_e\\)表明微分熵公式中底数为\\(e\\)，费希尔信息是关于随机变量分布的费希尔信息。特别地，若\\(t\\rightarrow 0\\)时极限存在，则\\(\\frac{\\partial}{\\partial t}h_e(X+\\sqrt{t}Z)\\big|_{t=0}=\\frac{1}{2}\\mathcal{I}(X)\\) 通常\\(t\\)被视作一种扰动。 卷积不等式 \\[\\frac{1}{\\mathcal{I}(X+Y)} \\geq \\frac{1}{\\mathcal{I}(X)} + \\frac{1}{\\mathcal{I}(Y)}\\] 熵幂不等式 设\\(\\mathbf{X}\\)和\\(\\mathbf{Y}\\)为相互独立的\\(n\\)维随机向量，它们的密度函数已知，则： \\[2^{\\frac{2}{n}h(\\mathbf{X}+\\mathbf{Y})}\\geq 2^{\\frac{2}{n}h(\\mathbf{X})}+2^{\\frac{2}{n}h(\\mathbf{Y})}\\] 对于两个独立的随机变量\\(X\\)和\\(Y\\)，\\(h(X+Y)\\geq h(X&#39;+Y&#39;)\\)，这里\\(X&#39;\\)和\\(Y&#39;\\)是相互独立的正态分布的随机变量，且满足\\(h(X&#39;)=h(X)\\)且\\(h(Y&#39;)=h(Y)\\)。 Fisher Information &amp; Natural Gradient 在概率分布函数具备良好性质时，Fisher信息矩阵和KL散度的Hesse矩阵的相反数相等。因而在牛顿迭代法中，使用Fisher信息矩阵代替Hesse矩阵，有时更易求解。 Natural Gradient（自然梯度法） \\[{\\displaystyle \\theta _{m+1}=\\theta _{m}+\\eta_m{\\mathcal {I}}^{-1}(\\theta _{m})V(\\theta _{m})}\\] （\\(V\\)为关于\\(\\theta\\)的得分函数） 自然梯度法考虑了参数的不同维度对目标函数不同的影响，加速了梯度下降法的收敛。 SGD（随机梯度下降）中，假设中心极限定理，随机梯度作为一个随机变量，满足正态分布。那么迭代中，相当于使用全部数据计算的梯度，附加上协方差矩阵，即：（\\(t\\)为mini-batch的规模） \\[{\\displaystyle \\theta _{m+1}=\\theta _{m}+\\eta_m V_0(\\theta _{m})}+\\frac{\\eta_m}{\\sqrt{t}}\\epsilon_m, \\epsilon_m\\sim\\mathcal{N}(0,\\hat{\\Sigma}(\\theta_m))\\] 上式中，协方差与目标函数的曲率在真实参数上相等。而在迭代过程中也近似相等。 这表明这样的SGD中的噪声遵循目标函数的曲率，使得迭代时更容易逃离局部的sharp minima，进入flat minima，从而得到泛化能力更强的解。因而使用自然梯度的随机梯度下降能获得更强的泛化能力，也通常能加快迭代速度。 References Wikipedia contributors, &quot;Fisher information —— Wikipedia, the free encyclopedia,&quot; 2019. [Online; accessed 24-May-2019]. T. M. Cover and J. A. Thomas, Elements of information theory. John Wiley &amp; Sons, 2012. J. Duchi, &quot;Lecture notes for statistics 311/electrical engineering 377,&quot; URL:https://stanford.edu/class/stats311/Lectures/full_notes.pdf . Last visited on, vol. 2, p. 23, 2016.","tags":[]},{"title":"形式语言与自动机","date":"2019-03-24T01:54:17.000Z","path":"2019/03/24/形式语言与自动机/","text":"上下文无关文法 设计上下文无关文法 {anbncmdm|n≥1,m≥1}∩{anbmcmdn|n≥1,m≥1} S-&gt;AB|T T-&gt;aTd|aCd A-&gt;aAb|ab B-&gt;cBd|cd C-&gt;bCc|bc {anbm|n,m≥0∧n≥m} S-&gt;A|B A-&gt;aA|aC B-&gt;Bb|Cb C-&gt;aCb|ε {anbm|n≥0,m≥0,3n≥m≥2n} S-&gt;aSbb|aSbbb|ε {w|w∈{a,b}*,w中a和b的数目不同} S-&gt;A|B A-&gt;AA|Ta B-&gt;BB|Tb T-&gt;aTbT|bTaT|ε 注意此处T生成a与b数目相同的字符串 {w|w∈{a,b}*,且w中a与b的数目相差为2} S-&gt;TaTaT|TbTbT T-&gt;aTbT|bTaT|ε 文法和语言中的二义性 文法无二义性：语法分析树唯一，亦等价于最左推导唯一 下面的文法生成的是具有x和y的操作数、二元运算符+、-和*的前缀表达式： E-&gt;+EE|*EE|-EE|x|y 证明这个文法是无歧义的。（Hopcroft, 5.4.7(b)） 提纲：可证明其最左推导是唯一的，对字符串长度归纳，同时归纳证明生成的字符串w所有非空后缀字符串中操作数个数多于运算符个数。 有限自动机 安利一个用来画自动机的app：http://madebyevan.com/fsm/ 设计DFA 长度至少为2且头两个字符不相同的0,1串构成的集合 0 1 -&gt;q0 q1 q2 q1 q4 q3 q2 q3 q4 *q3 q3 q3 q4 q4 q4 {w∈{a,b}*|w中不包含子串aa} a b -&gt;*q0 q1 q0 *q1 q2 q0 q2 q2 q2 {w∈{a,b}*|w中包含且仅包含奇数个子串ab} a b -&gt;q0 q1 q0 q1 q1 q2 *q2 q3 q2 q3 q3 q0 {w∈{a,b}*|w中a的个数和b的个数之和是奇数} a b -&gt;q0 q1 q1 *q1 q0 q0 {w∈{a,b}*|w含相同个数的a和b,且w的每个前缀中a和b个数之差不超过1} a b -&gt;*q0 q1 q2 q1 q3 q0 q2 q0 q3 q3 q3 q3 {w∈{a,b}*|w包含子串ab，但不包含子串bb} 相应的NFA有： 此NFA遇到子串ab时到达终态，如果是最后一个ab，则停留在终态，反之跳转回q1。 DFA的最小化 构造与该DFA等价的最小化的DFA： 填表算法第一步区分1，3，6与2，4，5 第二步区分2与4，5（输入字符b） 第三步区分1，3与6（输入字符a） 故最终等价类有{1, 3}, {2}, {4, 5}, {6} 最小化的DFA是 正规语言 设计正规语言 {xwxR|x,w∈(a+b)+},其中(a+b)+=(a+b)(a+b)*,xR为x的反向(即反转) a(a+b)(a+b)*a+b(a+b)(a+b)*(a+b) {w|w∈{a,b}*∧∃x,y(x,y∈{a,b}*∧w=xy∧|y|=3∧y=yR)} (a+b)*(aaa+aba+bab+bbb) {w∈{a,b}*|w中既不包含子串aa,也不包含子串bb} (ε+b)(ab)*(ε+a) {anbm|n,m≥0且n+m为偶数} (aa)*(bb)*+(aa)*a(bb)*b {w|w∈{a,b}*,|w|≥1,且w的后20位至少有一个a} (a+b)*a(a+b+ε)19 {w|w∈{a,b}*,|w|≥1,且当w以a结尾时,它的长度为奇数} ((a+b)(a+b))*a+(a+b)*b {w|w∈{a,b}*,|w|≥2,且w的前5位至少有一个子串aa} (a+b+ε)3aa(a+b)* {w|w∈{a,b}*,|w|≥2,且w的第2位至第5位至少有一个a} (a+b)(a+b+ε)3a(a+b)* {w|w∈{0,1}*,w至少含有3个1,且倒数第3位为1} (0+1)*1(0+1)*1(0+1)*100+(0+1)*1(0+1)*1(01+10)+(0+1)*111 有限状态自动机与正规表达式的关系 Thompson构造法 略 Kleene构造法&amp;状态消去法 运用状态消去法，消2，1到4的弧变为b(a+b)，4到自身的弧变为(a+b)2 最终的正则表达式为a*+a*b(a+b)((a+b)2)* 正规语言的性质 语言L由所有满足如下条件的0，1串构成：0的数目二倍于1的数目。试应用Pumping引理证明L不是正规语言。 对于任意n，取w=02n1n，任意满足w=xyz∧|xy|≤n∧y≠ε的x，y，z必有y全由0组成，则xy0z中0比1的两倍少，不在L中，L不是正规语言。 语言L由所有满足如下条件的0, 1串构成：0的数目多于1的数目（ 对0 和1 在串中出现的次序没有限制）。试应用Pumping引理证明L不是正规语言。 选w=0n+11n","tags":[]},{"title":"Hello, world!","date":"2019-03-24T01:53:12.000Z","path":"2019/03/24/Hello-world/","text":"这里会记录一些学习笔记，或者灌水，请多多指教！","tags":[]}]